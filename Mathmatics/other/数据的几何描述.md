#数据的几何描述
date: 2018-06-18 11:52:42
tags: [机器学习,数据挖掘]


## 数据矩阵
数据在经常表示为多行多列的样子，类似一个矩阵

数据矩阵的行经常被称作：样本，实例，数据点，记录
数据矩阵的列经常被称作：特征，属性，维度，变量


## 向量
具有大小(magnitude)和方向的量

向量的代数表示：$\vec{F}$,$\vec{AB}$,$\vec{a}$

向量的几何表示：用有向线段表示，长度表示向量的大小，方向表示向量的方向；长度为0的是`0向量`，长度为1的是`单位向量`

坐标表示：空间直角坐标系中，i,j,k为x轴，y轴和z轴的基底，若点P的坐标是(x,y,z)，从原点出发的向量$\vec{a}=\vec{OP}=xi+yj+zk$,其中(x,y,z)就是向量$\vec{a}$的坐标表示

## 向量空间
设K是一个数域，K中$m$个数$a_{1},a_{2} \cdots ,a_{m}$组成的m维向量是：



$$a = \begin{bmatrix}
   a_{1}  \\\\
   a_{2}  \\\\
   \vdots \\\\
   a_{m} \\\\
\end{bmatrix} (a_{i}\in{K},i=1,2,\cdots,m)$$

向量$a$所组成的集合记为$K^{m}$,则集合$K^{m}$和该集合内的**向量加法**和**数乘**这一个整体成为**数域$K$上的$m$维向量空间**

$K^{m}$中向量的加法、数乘有8条运算法则

## 标准基向量
第j个分量是1，其他分量是0

$$e_{i} = (0,\cdots,e_{i},\cdots,0)^{T} $$

## 向量的点乘
向量a和b如下：

$$
\begin{matrix}
a = \begin{pmatrix}a_{1} \\\\ a_{2}\\\\ \vdots \\\\ a_{m}\end{pmatrix} &
b = \begin{pmatrix}b_{1} \\\\ b_{2}\\\\ \vdots \\\\ b_{m}\end{pmatrix}
\end{matrix}
$$


向量a,b的点乘结果是标量

$$\begin{aligned}
a_{T}b &=(a_{1},a_{2},\cdots,a_{m}) \cdotp \begin{pmatrix} b_{1} \\\\ b_{2}\\\\ \vdots \\\\ b_{m} \end{pmatrix} \\\\
&= a_{1}b_{1}+a_{2}b_{2}+\cdots+a_{m}b_{m} \\\\
&=\displaystyle\sum_{i=1}^{m}a_{i}b_{i}
\end{aligned}$$

## 范数
$L_{p}$范数定义为：

$$\begin{aligned} \| a\| & =(|a_{1}|^{p}+|a_{2}|^{p}+\cdots+|a_{m}|^{p})^{\frac{1}{p}} \\\\
&=(\displaystyle\sum_{i=1}^{m}|a_{i}|^{p})^{\frac{1}{p}}
\end{aligned}$$

其中欧几里得距离是p=2的$L_{p}$范数的特例

向量a的**欧几里得范数**或**长度**定义为：
$$\Vert a\Vert=\sqrt{a^{T}a}=\sqrt{a_{1}^{2}+a_{2}^{2}+\cdots+a_{m}^{2}}=\sqrt{\displaystyle\sum_{i=1}^{m}a_{i}^{2}}$$

向量a的**单位向量**定义为：

$$u = \dfrac{a}{\Vert {a}\Vert}=(\dfrac{1}{\Vert a\Vert})a$$

## 角度
向量a,b之间的最小角的余弦值被称为**余弦相似度**,可以有a，b单位向量的点乘计算

$$\cos{\theta} = \dfrac{a^{T}b}{\Vert a\Vert \Vert b\Vert} = (\dfrac{a}{\Vert a\Vert})^{T}\dfrac{b}{\Vert b\Vert}$$

由柯西不等式：

$$|a^{T}b| \le \Vert a\Vert \Vert b\Vert$$

有:

$$-1\le\cos{\theta}\le 1$$


## 正交性

如果两个向量a,b是正交的，当且仅当$a^{T}b=0$,即a，b的余弦相似度为0，即两个向量的夹角为90°，

## 正交投影
向量b在向量a方向上的投影可以分解为：与a平行的部分$p=a_{\Vert}$ 和与a垂直（正交）的部分$r=b_{\bot}$,b可以表示为$b=a_{\Vert} + b_{\bot} = p+r$

p和a平行，则存在标量c是的$p=ca$；$r=b-p=b-ca$,有r与p正交，则有：

$$p^{T}r = (ca)^{T}(b-ca)=ca^{T}b-c^{2}a^{T}a=0$$

得：

$$c = \dfrac{a^{T}a}{a^{T}b}$$

得：

$$p = ca = (\dfrac{a^{T}a}{a^{T}b})a$$

## 线性无关

一组向量$v_{1},v_{2},\cdots,v_{k}$，其中至少一个向量能够被其他向量线性的表示，即对：

$$c_{1}v_{1}+c_{2}v_{2}+\cdots+c_{k}v_{k}=0$$

存在不全为0的常数$c_{i}$,(即$c_{1},c_{2},\cdots,c_{k}$至少有一个不为0)，称$v_{1},v_{2},\cdots,v_{k}$线性相关


若这k个向量线性无关，当且仅当：

$c_{1}v_{1}+c_{2}v_{2}+\cdots+c_{k}v_{k}=0$ 且$c_{1} =c_{2}=\cdots=c_{k}=0$

## 线性等价、秩

给定$K^{m}$内的两个向量组：

$\alpha_{1},\alpha_{2},\cdots,\alpha_{r}\qquad(1)$

$\beta_{1},\beta_{2},\cdots,\beta_{r}\qquad(2)$

向量组1和向量组2中的想能能够互相线性表示，则称向量组1和向量组2**线性等价**

假设：

向量组1中的向量都能够被向量组2的向量线性表示；

向量组2中的向量线性无关

则称向量组2是向量组1的**极大线性无关部分组**，也称为向量组2的**基**，或者是**基底**，

如果向量组2中的向量两两正交：称该基是向量组1的**正交基**,如果这些向量还是单位向量，则他们是向量组1的**标准正交基**


其中向量组2中向量的个数，称为向量组1的**秩**


